{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import random\n",
        "import tarfile\n",
        "import os\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, GRU, LSTM, Bidirectional, Dense\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/MyDrive/aclImdb_v1.tar.gz\"\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    tar.extractall(path=\"/content/drive/My Drive/\")\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Md5LsDI7D_U",
        "outputId": "1d89513f-84ca-4328-f3aa-c5b25c8e46d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8MGvSvjvZTb",
        "outputId": "5d00b723-33af-4fff-8920-31c685ad9c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in pos folder: 1984\n",
            "Number of files in neg folder: 2000\n"
          ]
        }
      ],
      "source": [
        "def preprocess(input_text):\n",
        "    # Convert text to lowercase\n",
        "    processed_text = input_text.lower()\n",
        "    # Remove punctuation\n",
        "    processed_text = processed_text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(processed_text)\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Reconstruct the preprocessed text\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "def load_and_preprocess(directory_path, max_files=None):\n",
        "    documents = []\n",
        "    file_count = 0\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        if max_files is not None and file_count >= max_files:\n",
        "            break\n",
        "        with open(os.path.join(directory_path, file_name), 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "            cleaned_content = preprocess(content)\n",
        "            documents.append(cleaned_content)\n",
        "        file_count += 1\n",
        "    return documents\n",
        "\n",
        "positive_directory = \"/content/drive/MyDrive/aclImdb/train/pos/\"\n",
        "negative_directory = \"/content/drive/MyDrive/aclImdb/train/neg/\"\n",
        "\n",
        "max_files_to_load = 2000\n",
        "positive_documents = load_and_preprocess(positive_directory, max_files_to_load)\n",
        "negative_documents = load_and_preprocess(negative_directory, max_files_to_load)\n",
        "\n",
        "print(\"Number of files in pos folder:\", len(positive_documents))\n",
        "print(\"Number of files in neg folder:\", len(negative_documents))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#combining documents\n",
        "all_documents = positive_documents + negative_documents\n",
        "all_labels = [1] * len(positive_documents) + [0] * len(negative_documents)\n",
        "#shuffling documents\n",
        "combined_data = list(zip(all_documents, all_labels))\n",
        "random.shuffle(combined_data)\n",
        "all_documents, all_labels = zip(*combined_data)"
      ],
      "metadata": {
        "id": "3UA4WSvM3b1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp_qfod8s5wj",
        "outputId": "d41ae2f9-522a-43c0-ccf3-5471bc529177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0, 0, 1, 0, 0, 1, 1, 1, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = np.array(all_labels)\n",
        "all_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2RB67zAtoUR",
        "outputId": "2ebf4736-7f59-45ab-c6d9-c1c9b8b8301d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentiment analysis using deep learning"
      ],
      "metadata": {
        "id": "N1Er_gFS3b1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spiliting data\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(all_documents, all_labels, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "RRWv_bqvnOor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bag of words using count vectorizer\n",
        "word_vectorizer = CountVectorizer(max_features=10000)\n",
        "train_bow = word_vectorizer.fit_transform(train_data)\n",
        "test_bow = word_vectorizer.transform(test_data)\n"
      ],
      "metadata": {
        "id": "zpXoh5Kpn7rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 100  # Maximum sequence length\n",
        "train_sequences = pad_sequences(train_bow.toarray(), maxlen=max_sequence_length)\n",
        "test_sequences = pad_sequences(test_bow.toarray(), maxlen=max_sequence_length)\n",
        "train_seq[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5VD2AeWoM0b",
        "outputId": "6e4f5d91-06b8-4bc8-afa3-973eaedea59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELS\n",
        "# RNN:\n",
        "def build_rnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=train_sequences.shape[1], output_dim=64, input_length=max_sequence_length))\n",
        "    model.add(SimpleRNN(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# GRU:\n",
        "def build_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=train_sequences.shape[1], output_dim=64, input_length=max_sequence_length))\n",
        "    model.add(GRU(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# LSTM:\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=train_sequences.shape[1], output_dim=64, input_length=max_sequence_length))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# BILSTM:\n",
        "def build_bilstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=train_sequences.shape[1], output_dim=64, input_length=max_sequence_length))\n",
        "    model.add(Bidirectional(LSTM(64)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "#splitting data\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_sequences, train_labels, test_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "id": "X1rBwCDNogWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING AND EVALUATION\n",
        "def train_and_evaluate(model_builder):\n",
        "    model = model_builder()\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "    y_pred = np.round(model.predict(test_sequences))\n",
        "    accuracy = accuracy_score(test_labels, y_pred)\n",
        "    precision = precision_score(test_labels, y_pred, zero_division=\"warn\")\n",
        "    recall = recall_score(test_labels, y_pred)\n",
        "    f1 = f1_score(test_labels, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "models = {'RNN': build_rnn_model, 'GRU': build_gru_model, 'LSTM': build_lstm_model, 'BiLSTM': build_bilstm_model}\n",
        "\n",
        "results = {}\n",
        "for model_name, model_builder in models.items():\n",
        "    accuracy, precision, recall, f1 = train_and_evaluate(model_builder)\n",
        "    results[model_name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr4sk17GoitW",
        "outputId": "784de4e2-93bd-45b5-8f12-6486448ab6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "85/85 [==============================] - 8s 71ms/step - loss: 0.6920 - accuracy: 0.5415 - val_loss: 0.7064 - val_accuracy: 0.4448\n",
            "Epoch 2/100\n",
            "85/85 [==============================] - 6s 68ms/step - loss: 0.6964 - accuracy: 0.5284 - val_loss: 0.7126 - val_accuracy: 0.4950\n",
            "Epoch 3/100\n",
            "85/85 [==============================] - 2s 27ms/step - loss: 0.6904 - accuracy: 0.5355 - val_loss: 0.6852 - val_accuracy: 0.5485\n",
            "Epoch 4/100\n",
            "85/85 [==============================] - 2s 26ms/step - loss: 0.6908 - accuracy: 0.5456 - val_loss: 0.7013 - val_accuracy: 0.5251\n",
            "Epoch 5/100\n",
            "85/85 [==============================] - 2s 28ms/step - loss: 0.7064 - accuracy: 0.4961 - val_loss: 0.6936 - val_accuracy: 0.4448\n",
            "Epoch 6/100\n",
            "85/85 [==============================] - 2s 29ms/step - loss: 0.6971 - accuracy: 0.4916 - val_loss: 0.6911 - val_accuracy: 0.5619\n",
            "32/32 [==============================] - 0s 7ms/step\n",
            "Epoch 1/100\n",
            "85/85 [==============================] - 10s 80ms/step - loss: 0.6936 - accuracy: 0.5065 - val_loss: 0.6951 - val_accuracy: 0.4415\n",
            "Epoch 2/100\n",
            "85/85 [==============================] - 5s 55ms/step - loss: 0.6939 - accuracy: 0.4861 - val_loss: 0.6944 - val_accuracy: 0.4448\n",
            "Epoch 3/100\n",
            "85/85 [==============================] - 7s 79ms/step - loss: 0.6934 - accuracy: 0.5050 - val_loss: 0.6915 - val_accuracy: 0.5619\n",
            "Epoch 4/100\n",
            "85/85 [==============================] - 5s 59ms/step - loss: 0.6936 - accuracy: 0.4853 - val_loss: 0.6914 - val_accuracy: 0.5619\n",
            "Epoch 5/100\n",
            "85/85 [==============================] - 5s 55ms/step - loss: 0.6934 - accuracy: 0.4905 - val_loss: 0.6935 - val_accuracy: 0.4615\n",
            "Epoch 6/100\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.6926 - accuracy: 0.4976 - val_loss: 0.6884 - val_accuracy: 0.4615\n",
            "Epoch 7/100\n",
            "85/85 [==============================] - 5s 56ms/step - loss: 0.6930 - accuracy: 0.4894 - val_loss: 0.6915 - val_accuracy: 0.4515\n",
            "Epoch 8/100\n",
            "85/85 [==============================] - 5s 56ms/step - loss: 0.6922 - accuracy: 0.5028 - val_loss: 0.6841 - val_accuracy: 0.4849\n",
            "Epoch 9/100\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.6917 - accuracy: 0.5009 - val_loss: 0.6912 - val_accuracy: 0.4448\n",
            "Epoch 10/100\n",
            "85/85 [==============================] - 5s 57ms/step - loss: 0.6921 - accuracy: 0.5058 - val_loss: 0.6879 - val_accuracy: 0.4816\n",
            "Epoch 11/100\n",
            "85/85 [==============================] - 6s 66ms/step - loss: 0.6913 - accuracy: 0.4890 - val_loss: 0.6857 - val_accuracy: 0.4883\n",
            "32/32 [==============================] - 1s 13ms/step\n",
            "Epoch 1/100\n",
            "85/85 [==============================] - 11s 91ms/step - loss: 0.6940 - accuracy: 0.4931 - val_loss: 0.6939 - val_accuracy: 0.4448\n",
            "Epoch 2/100\n",
            "85/85 [==============================] - 5s 63ms/step - loss: 0.6933 - accuracy: 0.4920 - val_loss: 0.6945 - val_accuracy: 0.4448\n",
            "Epoch 3/100\n",
            "85/85 [==============================] - 7s 83ms/step - loss: 0.6937 - accuracy: 0.4913 - val_loss: 0.6937 - val_accuracy: 0.4482\n",
            "Epoch 4/100\n",
            "85/85 [==============================] - 5s 62ms/step - loss: 0.6933 - accuracy: 0.5009 - val_loss: 0.6922 - val_accuracy: 0.5619\n",
            "Epoch 5/100\n",
            "85/85 [==============================] - 6s 67ms/step - loss: 0.6933 - accuracy: 0.5006 - val_loss: 0.6923 - val_accuracy: 0.5652\n",
            "Epoch 6/100\n",
            "85/85 [==============================] - 6s 73ms/step - loss: 0.6933 - accuracy: 0.4916 - val_loss: 0.6915 - val_accuracy: 0.5719\n",
            "Epoch 7/100\n",
            "85/85 [==============================] - 5s 60ms/step - loss: 0.6923 - accuracy: 0.5084 - val_loss: 0.6856 - val_accuracy: 0.4950\n",
            "Epoch 8/100\n",
            "85/85 [==============================] - 7s 81ms/step - loss: 0.6923 - accuracy: 0.4994 - val_loss: 0.6874 - val_accuracy: 0.5184\n",
            "Epoch 9/100\n",
            "85/85 [==============================] - 5s 62ms/step - loss: 0.6922 - accuracy: 0.5058 - val_loss: 0.6898 - val_accuracy: 0.4615\n",
            "Epoch 10/100\n",
            "85/85 [==============================] - 6s 67ms/step - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6841 - val_accuracy: 0.5619\n",
            "Epoch 11/100\n",
            "85/85 [==============================] - 6s 75ms/step - loss: 0.6907 - accuracy: 0.5296 - val_loss: 0.6837 - val_accuracy: 0.5084\n",
            "Epoch 12/100\n",
            "85/85 [==============================] - 5s 60ms/step - loss: 0.6902 - accuracy: 0.5028 - val_loss: 0.6811 - val_accuracy: 0.5719\n",
            "Epoch 13/100\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.6921 - accuracy: 0.4998 - val_loss: 0.6835 - val_accuracy: 0.5819\n",
            "Epoch 14/100\n",
            "85/85 [==============================] - 5s 62ms/step - loss: 0.6907 - accuracy: 0.5180 - val_loss: 0.6850 - val_accuracy: 0.5184\n",
            "Epoch 15/100\n",
            "85/85 [==============================] - 6s 69ms/step - loss: 0.6899 - accuracy: 0.5039 - val_loss: 0.6830 - val_accuracy: 0.5117\n",
            "32/32 [==============================] - 1s 16ms/step\n",
            "Epoch 1/100\n",
            "85/85 [==============================] - 15s 136ms/step - loss: 0.6938 - accuracy: 0.5032 - val_loss: 0.6904 - val_accuracy: 0.5452\n",
            "Epoch 2/100\n",
            "85/85 [==============================] - 9s 112ms/step - loss: 0.6804 - accuracy: 0.5712 - val_loss: 0.6600 - val_accuracy: 0.5753\n",
            "Epoch 3/100\n",
            "85/85 [==============================] - 10s 112ms/step - loss: 0.6706 - accuracy: 0.5846 - val_loss: 0.6551 - val_accuracy: 0.5819\n",
            "Epoch 4/100\n",
            "85/85 [==============================] - 11s 126ms/step - loss: 0.6685 - accuracy: 0.5649 - val_loss: 0.6578 - val_accuracy: 0.5719\n",
            "Epoch 5/100\n",
            "85/85 [==============================] - 10s 119ms/step - loss: 0.6653 - accuracy: 0.5861 - val_loss: 0.6520 - val_accuracy: 0.5853\n",
            "Epoch 6/100\n",
            "85/85 [==============================] - 9s 109ms/step - loss: 0.6641 - accuracy: 0.5857 - val_loss: 0.6451 - val_accuracy: 0.6120\n",
            "Epoch 7/100\n",
            "85/85 [==============================] - 11s 126ms/step - loss: 0.6666 - accuracy: 0.5850 - val_loss: 0.6455 - val_accuracy: 0.5987\n",
            "Epoch 8/100\n",
            "85/85 [==============================] - 10s 122ms/step - loss: 0.6593 - accuracy: 0.6006 - val_loss: 0.6612 - val_accuracy: 0.5619\n",
            "Epoch 9/100\n",
            "85/85 [==============================] - 9s 104ms/step - loss: 0.6556 - accuracy: 0.5972 - val_loss: 0.6310 - val_accuracy: 0.6054\n",
            "Epoch 10/100\n",
            "85/85 [==============================] - 11s 126ms/step - loss: 0.6533 - accuracy: 0.6062 - val_loss: 0.6411 - val_accuracy: 0.5853\n",
            "Epoch 11/100\n",
            "85/85 [==============================] - 11s 126ms/step - loss: 0.6512 - accuracy: 0.6002 - val_loss: 0.6329 - val_accuracy: 0.6054\n",
            "Epoch 12/100\n",
            "85/85 [==============================] - 9s 102ms/step - loss: 0.6503 - accuracy: 0.6065 - val_loss: 0.6332 - val_accuracy: 0.6087\n",
            "32/32 [==============================] - 2s 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing results\n",
        "print(\"Results:\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"\\t{metric_name}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qMRSV2xolw6",
        "outputId": "86ee4f6c-baf9-419c-f0c6-f134f9e6a369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "RNN: {'Accuracy': 0.5622489959839357, 'Precision': 0.5587761674718197, 'Recall': 0.6817288801571709, 'F1-score': 0.6141592920353982}\n",
            "GRU: {'Accuracy': 0.5080321285140562, 'Precision': 0.5102040816326531, 'Recall': 0.9332023575638507, 'F1-score': 0.6597222222222222}\n",
            "LSTM: {'Accuracy': 0.5190763052208835, 'Precision': 0.5231481481481481, 'Recall': 0.6660117878192534, 'F1-score': 0.5859982713915298}\n",
            "BiLSTM: {'Accuracy': 0.6164658634538153, 'Precision': 0.6135957066189625, 'Recall': 0.6738703339882122, 'F1-score': 0.6423220973782771}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentiment analysis using word embeddings"
      ],
      "metadata": {
        "id": "25OEgRN9x91N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, GRU, LSTM, Bidirectional, Dense\n",
        "#splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_documents, all_labels, test_size=0.25, random_state=42)\n",
        "#tokenizing\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequence = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequence = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_sequence, maxlen=maxlen)\n",
        "X_test_pad = pad_sequences(X_test_sequence, maxlen=maxlen)\n",
        "X_train_pad[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luPt9zW71pnO",
        "outputId": "5be95c4b-6dc4-459e-aeb2-50f40903574e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,  599, 1914, 1066,    1,   52,  504,\n",
              "        463, 1565,  981,    9,    2,  440,   16,  402, 1565,  318,   70,\n",
              "        233,    2,  169, 5647,  881,   33,    8, 3517, 1364,   16,    4,\n",
              "          1,    1,   87, 2234,   11,  285,  529,    5,  422,   49, 1336,\n",
              "        111], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad = np.array(X_train_pad)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "#MODELS WITH EMBEDDING\n",
        "#RNN\n",
        "def build_rnn_with_embedding():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=10000, output_dim=64, input_length=max_sequence_length))\n",
        "    model.add(SimpleRNN(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "#GRU\n",
        "def build_gru_with_embedding():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=10000, output_dim=64, input_length=max_sequence_length))\n",
        "    model.add(GRU(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "#LSTM\n",
        "def build_lstm_with_embedding():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=10000, output_dim=64, input_length=max_sequence_length))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "#BILSTM\n",
        "def build_bilstm_with_embedding():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=10000, output_dim=64, input_length=max_sequence_length))\n",
        "    model.add(Bidirectional(LSTM(64)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "tzWyRGEye3nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING AND EVALUATION\n",
        "def train_and_evaluate(model_builder):\n",
        "    model = model_builder()\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train_pad, y_train, epochs=8, batch_size=32, validation_split=0.1)\n",
        "    y_pred = np.round(model.predict(X_test_pad))\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "models = {'RNN with Embedding': build_rnn_with_embedding,'GRU with Embedding': build_gru_with_embedding,'LSTM with Embedding': build_lstm_with_embedding,'BiLSTM with Embedding': build_bilstm_with_embedding}\n",
        "\n",
        "results = {}\n",
        "for model_name, model_builder in models.items():\n",
        "    accuracy, precision, recall, f1 = train_and_evaluate(model_builder)\n",
        "    results[model_name] = {'Accuracy': accuracy,'Precision': precision,'Recall': recall,'F1-score': f1}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SqqSbZYzO0s",
        "outputId": "35c377d5-0941-4cb2-9c0e-7d7f3727abf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "85/85 [==============================] - 7s 67ms/step - loss: 0.6861 - accuracy: 0.5422 - val_loss: 0.6609 - val_accuracy: 0.6589\n",
            "Epoch 2/8\n",
            "85/85 [==============================] - 3s 38ms/step - loss: 0.3826 - accuracy: 0.8951 - val_loss: 0.5243 - val_accuracy: 0.7358\n",
            "Epoch 3/8\n",
            "85/85 [==============================] - 3s 39ms/step - loss: 0.0621 - accuracy: 0.9877 - val_loss: 0.5779 - val_accuracy: 0.7090\n",
            "Epoch 4/8\n",
            "85/85 [==============================] - 3s 38ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5405 - val_accuracy: 0.7692\n",
            "Epoch 5/8\n",
            "85/85 [==============================] - 5s 64ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.7826\n",
            "Epoch 6/8\n",
            "85/85 [==============================] - 3s 38ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.7960\n",
            "Epoch 7/8\n",
            "85/85 [==============================] - 3s 37ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.7893\n",
            "Epoch 8/8\n",
            "85/85 [==============================] - 4s 41ms/step - loss: 9.6966e-04 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.7926\n",
            "32/32 [==============================] - 0s 8ms/step\n",
            "Epoch 1/8\n",
            "85/85 [==============================] - 11s 84ms/step - loss: 0.6470 - accuracy: 0.6244 - val_loss: 0.5652 - val_accuracy: 0.7057\n",
            "Epoch 2/8\n",
            "85/85 [==============================] - 7s 86ms/step - loss: 0.2753 - accuracy: 0.8962 - val_loss: 0.3759 - val_accuracy: 0.8361\n",
            "Epoch 3/8\n",
            "85/85 [==============================] - 6s 75ms/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 0.4164 - val_accuracy: 0.8261\n",
            "Epoch 4/8\n",
            "85/85 [==============================] - 8s 95ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.4693 - val_accuracy: 0.8629\n",
            "Epoch 5/8\n",
            "85/85 [==============================] - 6s 74ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8662\n",
            "Epoch 6/8\n",
            "85/85 [==============================] - 8s 95ms/step - loss: 5.4284e-04 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.8829\n",
            "Epoch 7/8\n",
            "85/85 [==============================] - 6s 76ms/step - loss: 3.5321e-04 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.8696\n",
            "Epoch 8/8\n",
            "85/85 [==============================] - 8s 95ms/step - loss: 2.5176e-04 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8729\n",
            "32/32 [==============================] - 1s 24ms/step\n",
            "Epoch 1/8\n",
            "85/85 [==============================] - 9s 80ms/step - loss: 0.6493 - accuracy: 0.6311 - val_loss: 0.4967 - val_accuracy: 0.8428\n",
            "Epoch 2/8\n",
            "85/85 [==============================] - 8s 95ms/step - loss: 0.2763 - accuracy: 0.9271 - val_loss: 0.3126 - val_accuracy: 0.8562\n",
            "Epoch 3/8\n",
            "85/85 [==============================] - 6s 75ms/step - loss: 0.0743 - accuracy: 0.9836 - val_loss: 0.3551 - val_accuracy: 0.8930\n",
            "Epoch 4/8\n",
            "85/85 [==============================] - 8s 94ms/step - loss: 0.0389 - accuracy: 0.9926 - val_loss: 0.3647 - val_accuracy: 0.8829\n",
            "Epoch 5/8\n",
            "85/85 [==============================] - 6s 74ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.4589 - val_accuracy: 0.8629\n",
            "Epoch 6/8\n",
            "85/85 [==============================] - 8s 94ms/step - loss: 0.0250 - accuracy: 0.9959 - val_loss: 0.4059 - val_accuracy: 0.8763\n",
            "Epoch 7/8\n",
            "85/85 [==============================] - 6s 71ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.6281 - val_accuracy: 0.8629\n",
            "Epoch 8/8\n",
            "85/85 [==============================] - 8s 91ms/step - loss: 9.1466e-04 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.8829\n",
            "32/32 [==============================] - 1s 19ms/step\n",
            "Epoch 1/8\n",
            "85/85 [==============================] - 17s 155ms/step - loss: 0.5722 - accuracy: 0.6958 - val_loss: 0.3868 - val_accuracy: 0.8227\n",
            "Epoch 2/8\n",
            "85/85 [==============================] - 14s 167ms/step - loss: 0.2225 - accuracy: 0.9305 - val_loss: 0.4528 - val_accuracy: 0.8361\n",
            "Epoch 3/8\n",
            "85/85 [==============================] - 12s 138ms/step - loss: 0.0874 - accuracy: 0.9769 - val_loss: 0.4506 - val_accuracy: 0.8161\n",
            "Epoch 4/8\n",
            "85/85 [==============================] - 10s 114ms/step - loss: 0.1600 - accuracy: 0.9543 - val_loss: 0.5664 - val_accuracy: 0.8094\n",
            "Epoch 5/8\n",
            "85/85 [==============================] - 12s 137ms/step - loss: 0.0643 - accuracy: 0.9825 - val_loss: 0.5602 - val_accuracy: 0.8294\n",
            "Epoch 6/8\n",
            "85/85 [==============================] - 12s 137ms/step - loss: 0.0131 - accuracy: 0.9985 - val_loss: 0.5753 - val_accuracy: 0.8428\n",
            "Epoch 7/8\n",
            "85/85 [==============================] - 12s 136ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.7022 - val_accuracy: 0.8294\n",
            "Epoch 8/8\n",
            "85/85 [==============================] - 10s 111ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.7050 - val_accuracy: 0.8194\n",
            "32/32 [==============================] - 2s 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results:\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"\\t{metric_name}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ccDOT_z9L7",
        "outputId": "485d1ff4-17a7-4dfa-91cb-860687f10060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "RNN with Embedding: {'Accuracy': 0.7921686746987951, 'Precision': 0.7859848484848485, 'Recall': 0.8153241650294696, 'F1-score': 0.8003857280617165}\n",
            "GRU with Embedding: {'Accuracy': 0.8544176706827309, 'Precision': 0.8775933609958506, 'Recall': 0.831041257367387, 'F1-score': 0.8536831483350151}\n",
            "LSTM with Embedding: {'Accuracy': 0.8704819277108434, 'Precision': 0.8861788617886179, 'Recall': 0.8565815324165029, 'F1-score': 0.8711288711288712}\n",
            "BiLSTM with Embedding: {'Accuracy': 0.8604417670682731, 'Precision': 0.8530534351145038, 'Recall': 0.8781925343811395, 'F1-score': 0.8654404646660214}\n"
          ]
        }
      ]
    }
  ]
}